# Functions, lists and loops {#programming}




## Introduction

This chapter demonstrates some building blocks of programming with R. The main purpose here is to allow batch analyses - repeating similar tasks for many subsets of data. To do this, we first have to know how to write our own functions, so that we can apply the custom function to any new subset of data. This approach results in far less, and much more readable code than copy-pasting similar code for different datasets.

We also delve into "lists" in R, a versatile data object that you have worked with already - even if you didn't know it. Understanding lists well in R is the key to more complex analyses, and more readable workflows.

Finally we take a brief look at 'for loops', a basic programming utility that we rarely need in R, since almost all functions are vectorized. Sometimes it is however more convenient to use loops, or makes the code just a little more easy to work with.



```{r include=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(lgrdata))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(wrapr))
suppressPackageStartupMessages(library(ggplot2))

source("R/theme_datapelikaan.R")
library(showtext)
font_add_google(name = "Lato", family = "Lato", regular.wt = 400, bold.wt = 700)
theme_set(theme_datapelikaan(base_family = "Lato"))

library(knitr)
current_output <- opts_knit$get("rmarkdown.pandoc.to")
opts_knit$set(kable.force.latex = TRUE)
knit_theme$set("earendel")
opts_chunk$set(background="grey94", 
               fig.showtext = TRUE,
               dev = ifelse(current_output == "latex", "pdf", "svg"))

```


**Packages used in this chapter**

We use no new packages in this chapter except the `wrapr` package. All other functionality is included in base R, or commonly used packages `dplyr`, `ggplot2`, `lubridate`, and `lgrdata` for the example data.


## Writing functions {#writefunctions}

We have already used many built-in functions throughout this tutorial, but you can become very efficient at complex data tasks when you write your own simple functions. Writing your own functions can help with tasks that are carried out many times, which would otherwise result in a lot of code.

For example, suppose you frequently convert units from pounds to kilograms. It would be useful to have a function that does this, so you don't have to type the conversion factor every time. This is also good practice, as it reduces the probability of making typos.

```{r }
# This function takes a 'weight' argument and multiplies it with some number 
# to return kilograms.
poundsToKg <- function(weight){
  weight * 0.453592
}
```

We can use this `function` just like any other in R, for example, let's convert 'weight' to kilograms in the weightloss data.

```{r }
# Read data
library(lgrdata)
data(weightloss)

# Convert weight to kg.
weightloss$Weight <- poundsToKg(weightloss$Weight)
```

Let's write a function for the standard error of the mean, a function that is not built-in in R. 

```{r }
# Compute the standard error of the mean for a vector
SEmean <- function(x){
  se <- sd(x) / sqrt(length(x))
  return(se)
}
```

Here, the `function` SEmean takes one 'argument' called `x` (i.e., input), which is a numeric vector. The standard error for the mean is calculated in the first line, and stored in an object called `se`, which is then returned as output. We can now use the function on a numeric vector like this:

```{r }
# A numeric vector
unifvec <- runif(10, 1,2)

# The sample mean
mean(unifvec)

# Standard error for the mean
SEmean(unifvec)
```


```{block2 type="rmdtry"}
You can use functions that you defined yourself just like any other function, for example in `summaryBy`. First read in the `SEmean` function defined in the example above, and then use the cereal data to calculate the mean and SE of `rating` by `Manufacturer` (or use data of your choosing).
```




### Returning results

What if a function should return not just one result, as in the examples above, but many results? 

For example, this function computes the standard deviation and standard error of a vector, and returns both stored in a vector. Note that we also use the `SEmean` function, which we defined above.  

```{r }
# An function that computes the SE and SD of a vector
seandsd <- function(x){
  
  seresult <- SEmean(x)
  sdresult <- sd(x)

  # Store results in a vector with names
  vec <- c(SE = seresult, SD = sdresult)

return(vec)
}

# Test it:
x <- rnorm(100, mean=20, sd=4)
seandsd(x)
```

### Functions without arguments

Sometimes, a function takes no arguments (input) at all.

```{r }
sayhello <- function()message("Hello!")

sayhello()
```


We now know enough about writing functions to start using them in many real-world applications, but return to writing more advanced functions in Section \@ref(functionsadvanced).

First, we take a close look at the most versatile data structure in R : the list.


## Working with lists {#workinglists}

Sofar, we have worked a lot with vectors, with are basically strings of numbers or bits of text. In a vector, each element has to be of the same data type. Lists are a more general and powerful type of vector, where each element of the `list` can be anything at all. This way, lists are a very flexible type of object to store a lot of information that may be in different formats.

Lists can be somewhat daunting for the beginning `R` user, which is why most introductory texts and tutorials skip them altogether. However, with some practice, lists can be mastered from the start. Mastering a few basic skills with lists can really help increase your efficiency in dealing with more complex data analysis tasks.

To make a list from scratch, you simply use the `list` function. Here is a list that contains a numeric vector, a character vector, and a dataframe:

```{r }
mylist <- list(a=1:10, txt=c("hello","world"), dfr=data.frame(x=c(2,3,4),y=c(5,6,7)))
```

### Indexing lists

To extract an element from this list, you may do this by its name ('a','txt' or 'dfr' in this case), or by the element number (1,2,3). For lists, we use a double square bracket for indexing. Consider these examples,

```{r }
# Extract the dataframe:
mylist[["dfr"]]

# Is the same as:
mylist$dfr

# Extract the first element:
mylist[[1]]
```

Note that in these examples, the contents of the elements of the list are returned (for 'dfr', a dataframe), but the result itself is not a list anymore. If we select multiple elements, the result should still be a list. To do this, use the single square bracket.

Look at these examples:
```{r }
# Extract the 'a' vector, result is a vector:
mylist[['a']]

# Extract the 'a' vector, result is a list:
mylist['a']

# Extract multiple elements (result is still a list):
mylist[2:3]
```


### Converting lists to dataframes or vectors

Although lists are the most flexible way to store data and other objects in larger, more complex, analyses, ultimately you would prefer to output as a dataframe or vector.

Let's look at some examples using `do.call(rbind,...)` and `unlist`.
```{r }
# A list of dataframes:
dfrlis <- list(data1=data.frame(a=1:3,b=2:4), data2=data.frame(a=9:11,b=15:17))
dfrlis

# Since both dataframes in the list have the same number of columns and names, 
# we can 'successively row-bind' the list like this:
do.call(rbind, dfrlis)

# A list of vectors:
veclis <- list(a=1:3, b=2:4, f=9:11)

# In this case, we can use the 'unlist' function, which will 
# successively combine the three vectors into one:
unlist(veclis)
```

In real-world applications, some trial-and-error will be necessary to convert lists to more pretty formats.



### Combining lists

Combining two lists can be achieved using `c()`, like this:

```{r }
veclis <- list(a=1:3, b=2:4, f=9:11)
qlis <- list(q=17:15)
c(veclis,qlis)

# But be careful when you like to quickly add a vector
# the 'veclis'. You must specify list() like this
veclis <- c(veclis, list(r=3:1))
```


### Extracting output from built-in functions

One reason to gain a better understanding of lists is that many built-in functions return not just single numbers, but a diverse collection of outputs, organized in lists. Think of the linear model function (`lm`), it returns a lot of things at the same time (not just the p-value).

Let's take a closer look at the `lm` output to see if we can extract the adjusted R$^2$. 

```{r out.lines=10}
# Read data
data(allometry)

# Fit a linear model
lmfit <- lm(height ~ diameter, data=allometry)

# And save the summary statement of the model:
lmfit_summary <- summary(lmfit)

# We already know that simply typing 'summary(lmfit)' will give 
# lots of text output. How to extract numbers from there?
# Let's look at the structure of lmfit:
str(lmfit_summary)

# The output of lm is a list, so we can look at the names of # that list as well:
names(lmfit_summary)
```

So, now we can extract results from the summary of the fitted regression. Also look at the help file `?summary.lm`, in the section 'Values' for a description of the fields contained here.

To extract the adjusted R$^2$, for example:
```{r }
lmfit_summary[["adj.r.squared"]]

# Is the same as:
lmfit_summary$adj.r.squared
```


This sort of analysis will be very useful when we do many regressions, and want to summarize the results in a table.

```{block2 type="rmdtry"}
Run the code in the above examples, and practice extracting some other elements from the linear regression. Compare the output to the summary of the `lm` fit (that is, compare it to what `summary(lmfit)` shows on screen).
```


### Creating lists from dataframes {#dfrlists}

For more advanced analyses, it is often necessary to repeat a particular analysis many times, for example for sections of a dataframe. 

Using the `allom` data for example, we might want to split the dataframe into three dataframes (one for each species), and repeat some analysis for each of the species. One option is to make three subsets (using `subset`), and repeating the analysis for each of them. But what if we have hundreds of species? 

A more efficient approach is to `split` the dataframe into a list, so that the first element of the list is the dataframe for species 1, the 2nd element species 2, and so on. In case of the allom dataset, the resulting list will have three components. 

Let's look at an example on how to construct a list of dataframes from the allom dataset, one per species:

```{r allomsplit, cache=FALSE}
# Read allom data and make sure 'species' is a factor:
data(allometry)
is.factor(allometry$species)

# The levels of the factor variable 'species'
levels(allometry$species)

# Now use 'split' to construct a list:
allomsp <- split(allometry, allometry$species)

# The length of the list should be 3, with the names equal to the 
# original factor levels:
length(allomsp)
names(allomsp)
```


```{block2 type="rmdtry"}
Run the code in the above example, and confirm that `allomsp[[2]]` is identical to taking a subset of `allom` of the second species in the dataset (where 'second' refers to the second level of the factor variable `species`, which you can find out with `levels`).
```

Let's look at an example using the `hydro` data. The data contains water levels of a hydrodam in Tasmania, from 2005 to 2011.

```{r hydrosplit, cache=FALSE}
# Read hydro data, and convert Date to a proper date class.
data(hydro)

library(lubridate)
library(dplyr)

hydro <- mutate(hydro, 
                Date = dmy(Date),
                year = year(Date))

# Look at the Date range:
range(hydro$Date)

# Let's get rid of the first and last years (2005 and 2011) since they are incomplete
hydro <- filter(hydro, !year %in% c(2005,2011))

# Now split the dataframe by year. This results in a list, where every
# element contains the data for one year:
hydrosp <- split(hydro, hydro$year)

# Properties of this list:
length(hydrosp)
names(hydrosp)
```

To extract one element of the two lists that we created (`allomsp` and `hydrosp`), recall the section on indexing lists.


### Applying functions to lists {#lapply}

We will introduce two basic tools that we use to apply functions to each element of a list: `sapply` and `lapply`. The `lapply` function always returns a list, whereas `sapply` will attempt to `s`implify the result. When the function returns a single value, or a vector, `sapply` can often be used. In practice, try both and see what happens!


#### Using `sapply`

First let's look at some simple examples:

```{r }
# Let's make a simple list with only numeric vectors (of varying length)
numlis <- list(x=1000, y=c(2.1,0.1,-19), z=c(100,200,100,100))

# For the numeric list, let's get the mean for every element, and count 
# the length of the three vectors.
# Here, sapply takes a list and a function as its two arguments,
# and applies that function to each element of the list.
sapply(numlis, mean)
sapply(numlis, length)
```


You can of course also define your own functions, and use them here. Let's look at another simple example using the `numlis` object defined above. 

For example,  
```{r }
# Let's find out if any diameters are duplicated in the allom dataset.
# A function that does this would be the combination of 'any' and 'duplicated',
anydup <- function(vec)any(duplicated(vec))
# This function returns TRUE or FALSE

# Apply this function to numlis (see above):
sapply(numlis, anydup)

# You can also define the function on the fly like this:
sapply(numlis, function(x)any(duplicated(x)))
```


Now, you can use any function in `sapply` as long as it returns a single number based on the element of the list that you used it on. Consider this example with `strsplit`.

```{r }
# Recall that the 'strsplit' (string split) function usually returns a list of values. 
# Consider the following example, where the data provider has included the units in 
# the measurements of fish lengths. How do we extract the number bits?
fishlength <- c("120 mm", "240 mm", "159 mm", "201 mm")

# Here is one solution, using strsplit
strsplit(fishlength," ")

# We see that strsplit returns a list, let's use sapply to extract only 
# the first element (the number)
splitlen <- strsplit(fishlength," ")
sapply(splitlen, function(x)x[1])

# Now all you need to do is use 'as.numeric' to convert these bits of text to numbers.
```

The main purpose of splitting dataframes into lists, as we have done above, is so that we can save time with analyses that have to be repeated many times. In the following examples, you must have already produced the objects `hydrosp` and `allomsp` (from examples in the previous section).Both those objects are *lists of dataframes*, that is, each element of the list is a dataframe in itself. Let's look at a few examples with `sapply` first.

```{r sapplyexamples}
# How many observations per species in the allom dataset?
sapply(allomsp, nrow)
# Here, we applied the 'nrow' function to each separate dataframe.
# (note that there are easier ways to find the number of observations per species!,
# this is just illustrating sapply.)

# Things get more interesting when you define your own functions on the fly:
sapply(allomsp, function(x)range(x$diameter))
# Here, we define a function that takes 'x' as an argument:
# sapply will apply this function to each element of the list,
# one at a time. In this case, we get a matrix with ranges of the diameter per species.

# How about the correlation of two variables, separate by species:
sapply(allomsp, function(x)cor(x$diameter, x$height))


# For hydro, find the number of days that storage was below 235, for each year.
sapply(hydrosp, function(x)sum(x$storage < 235))

```


#### Using `lapply`


The `lapply` function is much like `sapply`, except it always returns a list.

For example, 
```{r lapplyexamples, out.lines=10}
# Get a summary of the hydro dataset by year:
lapply(hydrosp, summary)
```

Suppose you have multiple similar datasets in your working directory, and you want to read all of these into one list, use `lapply` like this (run this example yourself and inspect the results).
```{r eval=FALSE}
# Names of your datasets:
filenames <- c("pupae.csv","pupae.csv","pupae.csv")
# (This toy example will read the same file three times).

# Read all files into one list,
alldata <- lapply(filenames, read.csv)

# Then, if you are sure the datasets have the same number of columns and names,
# use do.call to collapse the list:
dfrall <- do.call(rbind, alldata)
```

```{block2 type="rmdtry"}
Recall the use of `dir` to list files, and even to find files that match a specific pattern (see Section \@ref(fileswd). Read all CSV files in your working directory (or elsewhere) into a single list, and count the number of rows for each dataframe.
```

Finally, we can use `lapply` to do all sorts of complex analyses that return any kind of object. The use of `lapply` with lists ensures that we can organize even large amounts of data in this way.

Let's do a simple linear regression of log(leafarea) on log(diameter) for the Allometry dataset, by species:

```{r }
# Run the linear regression on each element of the list, store in a new object:
lmresults <- lapply(allomsp, function(x)lm(log10(leafarea) ~ log10(diameter), data=x))

# Now, lmresults is itself a list (where each element is an object as returned by lm)
# We can extract the coefficients like this:
sapply(lmresults, coef)
# This shows the intercept and slope by species.
# Also look at (results not shown):
# lapply(lmresults, summary) 

# Get R2 for each model. First write a function that extracts it.
getR2 <- function(x)summary(x)$adj.r.squared
sapply(lmresults, getR2)
```

```{block2 type="rmdtry"}
Try to fully understand the difference between `sapply` and `lapply` by using `lapply` in some of the examples where we used `sapply` (and vice versa).
```


## Loops {#simpleloops}

Loops can be useful when we need to repeat certain analyses many times, and it is difficult to achieve this with `lapply` or `sapply`. To understand how a `for` loop works, look at this example:

```{r }
for(i in 1:5){
  message(i)
}
```

Here, the bit of code between {} is executed five times, and the object `i` has the values 1,2,3,4 and 5, in that order. Instead of just printing `i` as we have done above, we can also index a vector with this object:

```{r }
# make a vector
myvec <- round(runif(5),1)

for(i in 1:length(myvec)){
  message("Element ", i, " of the vector is: ", myvec[i])
}
```

Note that this is only a toy example: the same result can be achieved by simply typing `myvec`.

Now let's look at a useful application of a `for` loop: producing multiple plots in a `pdf`, using the `allomsp` object we created earlier.

This bit of code produces a `pdf` in your current working directory. If you can't find it, recall that you can use `getwd`() to get the current working directory.

```{r eval=FALSE}
# Open a pdf to send the plots to:
pdf("Allom plot by species.pdf", onefile=TRUE)
for(i in 1:3){
  with(allomsp[[i]],
       plot(diameter, leafarea, pch=15, xlim=c(0,80), ylim=c(0,450),
            main=levels(allom$species)[i]))
}
# Close the pdf (important!)
dev.off()
```

Here, we create three plots (`i` goes from 1 to 3), every time using a different element of the list `allomsp`. First, `i` will have the value 1, so that we end up using the dataframe `allomsp[[1]]`, the first element of the list. And so on. Take a look at the resulting PDF to understand how the code works.

*Note:* On windows (with Adobe reader) If the pdf (`Allom plot by species.pdf`) is open, the above will fail. If you try this anyway, close the pdf and try again. You may have to run the command `dev.off`() another time to make sure the device is ready.


Another way to achieve the same result is to avoid splitting the dataframe into a list first, and simply take subsets on the fly. Consider this template (make your own working example based on any dataset).

We assume here you have a dataframe called 'dataset' with a factor 'species', for which you want to create separate plots of Y vs. X.

```{r eval=FALSE}
pdf("somefilename.pdf", onefile=TRUE)
for(lev in levels(dataset$species)){
  
  with(subset(dataset, species==lev),
       plot(X,Y, 
            main=as.character(lev)))
}
dev.off()
```



## Writing functions: advanced concepts



### Wrapper functions {#wrapfunctions}

We often need to write simple functions that adjust one or two arguments to other functions. For example, suppose we often make plots with filled circles, with our favorite color ("dimgrey") :

```{r eval=FALSE}
library(lgrdata)
data(howell)
plot(age, height, data=howell, pch=19, col="dimgrey")
```

We could of course *always* specify these arguments, or we can write a function that sets those defaults. It would look like the following, except this function is incomplete, since we have *hardcoded* the other plotting arguments (the dataset, and the x and y variables):

```{r eval=FALSE}
# This function is not how we want it yet!
plot_filled_grey <- function(){
  plot(age, height, data=howell, pch=19, col="dimgrey")
}
```

We would like to be able to call the function via `plot_filled_grey(age, height, data=howell)`, in other words all arguments to our *wrapper function* should be passed to the underlying function. We have a very handy utility in R to do this, the three dots (`...`) :

```{r eval=FALSE}
plot_filled_grey <- function(...){
  plot(..., pch=19, col="dimgrey")
}
```

The function now works as intended. It can be further improved if we realize that the plotting color cannot be changed - it is always "dimgrey". We want the *default* value to be "dimgrey", but with an option to change it. This can be achieved like so,

```{r eval=FALSE}
plot_filled_grey <- function(..., col="dimgrey"){
  plot(..., pch=19, col=col)
}
```

Here, `col=col` sets the color in the call to `plot` with the default value specified in the wrapper function ("dimgrey"), but the user can also change it as usual.

```{block2 type="rmdtry"}
Take the `plot_filled_grey` function above, test it on some data, and modify it so that the plotting symbol can also be changed, but has a default value of 19.
```


### Wrapper functions to `ggplot2` or `dplyr`

In the previous section we saw how to write wrapper functions, functions that change a few arguments to some other function. These sort of functions are very helpful because we can save a lot of space by reusing a certain template. Suppose we want to make a plot with `ggplot2`, a simple scatter plot. We can achieve this via (result not shown),

```{r eval=FALSE}
data(howell)
library(ggplot2)

ggplot(howell, aes(x = weight, y = height)) +
  geom_point(size = 0.8, col = "dimgrey") +
  stat_smooth(method = "loess", span = 0.7, col="black")
```

We already used quite a bit of code for this simple plot, but imagine you have set various other options, formatting changes, axis limits and so on - you end up with a lot of code for one plot. If we want to reuse the code for another plot, for two other variables from the same dataframe, copy-pasting the code and modifying leads to even more code. 

Writing wrapper functions for `ggplot2` (or `dplyr`, see below, or many other cases) is more difficult because the arguments in the `ggplot2` code we want to change (height and weight) *are not quoted* - they are variables inside a dataframe (`howell` in our case). 

Suppose we have defined somewhere (perhaps as arguments in a function) that the following two variables should be used for the plot:

```{r eval=FALSE}
xvar <- "weight"
yvar <- "height"
```

If we use the same code as in the previous example, it does not work because the variable names need to be *not quoted*. The following (rather obscure) syntax converts the quoted variable name, to a variable to be found within the provided data.

```{r}
ggplot(howell, aes(x = !!sym(xvar), y = !!sym(yvar))) +
geom_point(size = 0.8, col = "dimgrey")
```


We can now write a wrapper function for a `ggplot2` plot. The same approach works for many other similar wrapper functions, for example around `dplyr` operations.

```{r eval=FALSE}
# Make a scatter plot with the howell data.
plot_scatter_howell <- function(xcol, ycol){
    ggplot(howell, aes(x = !!sym(xcol), y = !!sym(ycol))) +
    geom_point(size = 0.8, col = "dimgrey")
}

# The function can be used with quoted names:
plot_scatter_howell("height", "weight")
```


To also pass the dataset as an argument (making the function more general), we do not have to use any special syntax, but can immediately set it as an argument. The special syntax only applies when we are looking for variables in a dataframe.

```{r eval=FALSE}
# Our function now also takes a dataset as an argument
plot_scatter_howell2 <- function(xcol, ycol, dataset){
  
  ggplot(dataset, aes(x = !!sym(xvar), y = !!sym(yvar))) +
  geom_point(size = 0.8, col = "dimgrey")
  
}

# We can use it as,
plot_scatter_howell2("height", "weight", dataset = howell)
```





### Functions that take vectors as input

Many functions in R are *vectorized*, which means you can send a *vector* as an argument and the function will be automatically evaluated for each element of the vector. For example:

```{r}
# Count nr of characters in one string:
nchar("A sentence")

# the first argument to nchar() is vectorized:
nchar(c("A sentence", "is", "useful"))
```

Not all functions are vectorized, and when you write your own more complex functions you will often run into situations where you would like an argument to be vectorized but run into difficulty.

Take the following example:

```{r}

# A complex calculation. 
# If x is less than "change_val" (default 5), 
# return the product, otherwise the sum.
multiplex <- function(x, change_val = 5){
  
  if(x < change_val){
    prod(1:x)
  } else {
    sum(1:x)
  }
  
}

# This should give 4*3*2*1
multiplex(4)
```

A function like this is really only useful if it is vectorized over `x`, but it does not work as intended:

```{r}
# The function is not vectorized over x:
multiplex(x = c(4,8))

# ... or change_val
multiplex(x = 5, change_val = c(4,6))
```

You have at least 3 ways to vectorize any function. If you are only interested in vectorizing one argument at a time, you can use `sapply` as we have seen before:

```{r}
sapply(c(4,8), multiplex)
```


For more than one argument at a time you can use the flexible `mapply`, which allows us to specify the arguments to the function as vectors or lists:

```{r}
# First call multiplex(x=4, change_val = 3), then 
# multiplex(x=8, change_val = 7)
mapply(multiplex, x = c(4,8), change_val = c(3,7))
```

Using `mapply` you can write your own wrapper functions (\@ref(wrapfunctions)) quite easily. If this is too much work for you, consider using the rather magical `Vectorize` (which really is itself a wrapper around `mapply`):

```{r}
multiplex2 <- Vectorize(multiplex)
multiplex2(c(4,8))
```

Inspect `?Vectorize` to find that you can specify which arguments will be vecrorized, and whether to *simplify* the result (which works akin to `sapply`, making a vector or a matrix of a result where possible).


A final option is to write a *recursive* function that wraps around itself, executing the function once when the argument is not vectorized, and otherwise using `sapply` or `mapply` to return a vector of results:


```{r}
multiplex3 <- function(x){
  
  # Make the calculation when a single argument given:
  if(length(x) == 1){
    if(x < 5){
      prod(1:x)
    } else {
      sum(1:x)
    }  
  } else {
    
    # Otherwise use sapply, each time calling *this function*,
    # recursively.
    sapply(x, multiplex3)
  }
  
}

multiplex3(c(4,8))

```

This final solution can be found in many base R functions, and is a flexible interface to allow vectorized arguments.



```{r eval = FALSE, echo = FALSE}
# three methods same speed
vals <- sample(3:10, 10^4, replace = TRUE)

library(microbenchmark)
microbenchmark(
  mapply(multiplex, x = vals),
  multiplex2(vals),
  multiplex3(vals)
)
```


### If, then, else ... switch

We have already seen the basic `if` statement in many examples, which can be extended with multiple `else if` statements:

```{r}
# NOT an elegant use of multiple if statements.
animal_weight <- function(animal){
  
  if(animal == "cat"){
    weight <- 10
  } else if(animal == "cow"){
    weight <- 1000
  } else if(animal == "mouse"){
    weight <- 1
  } else if(animal == "dog"){
    weight <- 20
  }
  
return(weight)
}


animal_weight("dog")

```

The use of many `if` statements like this cause a lot of repetitive code. Usually if you have many `if then else` statements, you can either think of a simpler design for your function, or you can use `switch` where appropriate:

```{r}
animal_weight <- function(animal){
  
  
  weight <- switch(animal, 
                   mouse = 1,
                   cat = 10,
                   dog = 20,
                   cow = 1000,
                   NA)  # Return NA if the animal is not one of those above
                   
return(weight)
}

```

Here `switch` improves the readability of the code a lot. If you want to *switch* a numeric input, `switch` is perhaps not the best solution, unless it makes sense to evaluate the number as a character:

```{r}
num <- 3

switch(as.character(num),
       "1" = "Door number one.",
       "2" = "Door number two.",
       "3" = "Door number three."
       )
```





### Robust functions: defensive programming


Once you write more functions that perhaps become more generic and widely applicable within your projects, you want these functions to be more robust, that is, to fail less often and more elegantly. Functions fail if the wrong inputs were provided to them (by a careless programmer or data faults), or if some (rare) exception is reached. In this section we will look at a few tools to help you write more robust functions.


#### Argument matching

Returning to our `animal_weight` function from the previous section, 

```{r}
# A slightly shorter version of animal_weight().
animal_weight <- function(animal){
  switch(animal, 
             mouse = 1,
             cat = 10,
             dog = 20,
             cow = 1000,
             NA)
              
}
```

Here the last argument to `switch` indicates the value to return if the animal does not match any of the above. What if instead we want the function to stop and return a message if the value of the argument is not supported by the function? We can use `match.arg`, as follows:

```{r}
# Define animal_weight2 as a function which only allows 4 types of animal:
animal_weight2 <- function(animal = c("mouse","cat","dog","cow")){
  
  animal <- match.arg(animal)
  
  switch(animal, 
             mouse = 1,
             cat = 10,
             dog = 20,
             cow = 1000)
              
}

# Now see what happens when we give a wrong animal:
animal_weight2("giraffe")
```

Using `match.arg` resulted in a *very clear error message*. This sort of message makes it easy to find the source of the error. 

A side-effect of using `match.arg` is that it performs *partial matching*, meaning you can also call the function with only part of the argument value, for example try `animal_weight("mo")`. Personally I dislike partial matching as it rarely benefits us, but can cause problems that are hard to find. Probably best to not rely on it in any real code, though it can help save a few key strokes.
 

#### Argument checking

--> exercise: vectorize animal_weight

```{r}

sentence_case <- function(x){
  
  stopifnot(is.character(x))
  
  w <- sapply(strsplit(x, " "), function(ch){
    substr(ch,1,1) <- toupper(substr(ch,1,1))  
    return(ch)
  })
  
  paste(w, collapse = " ")
  
}

sentence_case("breaking news: man arrested for everything")


sentence_case(100)
```

stopifnot
missing
warning
stop
on.exit
try






## Exercises

```{r child="exercises/10_programming_exercises.Rmd", echo=FALSE, results='hide', fig.show='hide'}

```





